{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport math\nimport random\nimport pickle\nimport itertools\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \n\nfrom sklearn.utils import shuffle\n\nfrom scipy.signal import resample\n\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nimport pickle\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Conv1D, MaxPooling1D, Softmax, Add, Flatten, Activation# , Dropout\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\ndf2 = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\ndf = pd.concat([df, df2], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"494fc8a26ba40beb73fc1a4f7b219b213fb7705e","collapsed":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5281cb19f54f3bd379f875c24ae52b3b15fcafaf","collapsed":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fac0fb658ea34b48055838b4ad85078e883360d","collapsed":true},"cell_type":"code","source":"df[187].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"147b7604bd8a389d7f6aa111f38ae308af7c4eb7","collapsed":true},"cell_type":"code","source":"M = df.values\nX = M[:, :-1]\ny = M[:, -1].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"504d95532114efa4cc581d80bf02159c3ce519c6"},"cell_type":"code","source":"del df\ndel df2\ndel M","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"425c4b7abe39a14c6f81f8a71094cc1024276935"},"cell_type":"markdown","source":"# Visual Input"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bcd502ecd1eb95bbf8af983396d3d0c3fb50ce4b"},"cell_type":"code","source":"C0 = np.argwhere(y == 0).flatten()\nC1 = np.argwhere(y == 1).flatten()\nC2 = np.argwhere(y == 2).flatten()\nC3 = np.argwhere(y == 3).flatten()\nC4 = np.argwhere(y == 4).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85209065f110cea77f4d65053d1164e9ee816049","collapsed":true},"cell_type":"code","source":"x = np.arange(0, 187)*8/1000\n\nplt.figure(figsize=(20,12))\nplt.plot(x, X[C0, :][0], label=\"Cat. N\")\nplt.plot(x, X[C1, :][0], label=\"Cat. S\")\nplt.plot(x, X[C2, :][0], label=\"Cat. V\")\nplt.plot(x, X[C3, :][0], label=\"Cat. F\")\nplt.plot(x, X[C4, :][0], label=\"Cat. Q\")\nplt.legend()\nplt.title(\"1-beat ECG for every category\", fontsize=20)\nplt.ylabel(\"Amplitude\", fontsize=15)\nplt.xlabel(\"Time (ms)\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c269ab78773e4b5a960a5e55d2b48c53d5f9c446"},"cell_type":"markdown","source":"# Data augmentation\n\nTo train properly the model, we sould have to augment all data to the same level. Nevertheless, for a first try, we will just augment the smallest class to the same level as class 1. With that we will be able to have a test set of around 5x800 observations."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a332bfa2765ee6f5d49320c9d8f0b9c5795a4843"},"cell_type":"code","source":"def stretch(x):\n    l = int(187 * (1 + (random.random()-0.5)/3))\n    y = resample(x, l)\n    if l < 187:\n        y_ = np.zeros(shape=(187, ))\n        y_[:l] = y\n    else:\n        y_ = y[:187]\n    return y_\n\ndef amplify(x):\n    alpha = (random.random()-0.5)\n    factor = -alpha*x + (1+alpha)\n    return x*factor\n\ndef augment(x):\n    result = np.zeros(shape= (4, 187))\n    for i in range(3):\n        if random.random() < 0.33:\n            new_y = stretch(x)\n        elif random.random() < 0.66:\n            new_y = amplify(x)\n        else:\n            new_y = stretch(x)\n            new_y = amplify(new_y)\n        result[i, :] = new_y\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8673145476e0307f487a502e3590b76f2589acef","collapsed":true},"cell_type":"code","source":"plt.plot(X[0, :])\nplt.plot(amplify(X[0, :]))\nplt.plot(stretch(X[0, :]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"43f671858db58465b14b7fd7656ffa8381f7ea86"},"cell_type":"code","source":"result = np.apply_along_axis(augment, axis=1, arr=X[C3]).reshape(-1, 187)\nclasse = np.ones(shape=(result.shape[0],), dtype=int)*3\nX = np.vstack([X, result])\ny = np.hstack([y, classe])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c42605d020fd51885437f4af3cf10cebbeafc9bb"},"cell_type":"markdown","source":"# Split"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c136b567ed0cf450ed0476464c3b59d1ff1bb032"},"cell_type":"code","source":"subC0 = np.random.choice(C0, 800)\nsubC1 = np.random.choice(C1, 800)\nsubC2 = np.random.choice(C2, 800)\nsubC3 = np.random.choice(C3, 800)\nsubC4 = np.random.choice(C4, 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"52573d0c3a715cd693e682227d01f5a73549e421"},"cell_type":"code","source":"X_test = np.vstack([X[subC0], X[subC1], X[subC2], X[subC3], X[subC4]])\ny_test = np.hstack([y[subC0], y[subC1], y[subC2], y[subC3], y[subC4]])\n\nX_train = np.delete(X, [subC0, subC1, subC2, subC3, subC4], axis=0)\ny_train = np.delete(y, [subC0, subC1, subC2, subC3, subC4], axis=0)\n\nX_train, y_train = shuffle(X_train, y_train, random_state=0)\nX_test, y_test = shuffle(X_test, y_test, random_state=0)\n\ndel X\ndel y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7ae5108c9741b85f0f599cce51daf99df4733ed1"},"cell_type":"code","source":"X_train = np.expand_dims(X_train, 2)\nX_test = np.expand_dims(X_test, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbd350e57b2a44b4bf6a79f02c32dabb803e4855","collapsed":true},"cell_type":"code","source":"print(\"X_train\", X_train.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"X_test\", X_test.shape)\nprint(\"y_test\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ddf1e7b397de3c413fc991945d2d7f09df67da1","collapsed":true},"cell_type":"code","source":"ohe = OneHotEncoder()\ny_train = ohe.fit_transform(y_train.reshape(-1,1))\ny_test = ohe.transform(y_test.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16c106c2702045790367fc49d7223560fc613d75","collapsed":true},"cell_type":"code","source":"print(\"X_train\", X_train.shape)\nprint(\"y_train\", y_train.shape)\nprint(\"X_test\", X_test.shape)\nprint(\"y_test\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4de23b85abe34a726eab268171da0e827bafa35"},"cell_type":"markdown","source":"# Model\n\nNow let's re-create the model from the ArXiv Document"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fb0dc9775ddfa761c0ad948d59020fcbd2681c57"},"cell_type":"code","source":"n_obs, feature, depth = X_train.shape\nbatch_size = 500","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e70fab0b07290e042ba9cd7c6cba37462a457b03","collapsed":true},"cell_type":"code","source":"K.clear_session()\n\ninp = Input(shape=(feature, depth))\nC = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n\nC11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\nA11 = Activation(\"relu\")(C11)\nC12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\nS11 = Add()([C12, C])\nA12 = Activation(\"relu\")(S11)\nM11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n\n\nC21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\nA21 = Activation(\"relu\")(C21)\nC22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\nS21 = Add()([C22, M11])\nA22 = Activation(\"relu\")(S11)\nM21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n\n\nC31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\nA31 = Activation(\"relu\")(C31)\nC32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\nS31 = Add()([C32, M21])\nA32 = Activation(\"relu\")(S31)\nM31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n\n\nC41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\nA41 = Activation(\"relu\")(C41)\nC42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\nS41 = Add()([C42, M31])\nA42 = Activation(\"relu\")(S41)\nM41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n\n\nC51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\nA51 = Activation(\"relu\")(C51)\nC52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\nS51 = Add()([C52, M41])\nA52 = Activation(\"relu\")(S51)\nM51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n\nF1 = Flatten()(M51)\n\nD1 = Dense(32)(F1)\nA6 = Activation(\"relu\")(D1)\nD2 = Dense(32)(A6)\nD3 = Dense(5)(D2)\nA7 = Softmax()(D3)\n\nmodel = Model(inputs=inp, outputs=A7)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fdc0d8aa8475330af8d8e652d0b9ce214da66956"},"cell_type":"code","source":"def exp_decay(epoch):\n    initial_lrate = 0.001\n    k = 0.75\n    t = n_obs//(10000 * batch_size)  # every epoch we do n_obs/batch_size iteration\n    lrate = initial_lrate * math.exp(-k*t)\n    return lrate\n\nlrate = LearningRateScheduler(exp_decay)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"abcd2f0e8488c8f3b33cd6ed9ca7fd60fa44404b"},"cell_type":"code","source":"adam = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"812e637ae56f6a4be9c8e98d3b501cfb11ef78cb"},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e6ef643f6a55ab5b3c1b46126832c3ac45a6a2b","collapsed":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, \n                    epochs=75, \n                    batch_size=batch_size, \n                    verbose=2, \n                    validation_data=(X_test, y_test), \n                    callbacks=[lrate])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d43023d26a87e3c4702b96bea5962c990c76aa0a"},"cell_type":"code","source":"y_pred = model.predict(X_test, batch_size=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"20cfe7f5891e3c26c599fa4cd728ac0a499ac70e"},"cell_type":"code","source":"print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"017f2431a45766fb0d4b2ef17ce613c1142ca085"},"cell_type":"code","source":"print(\"ranking-based average precision : {:.3f}\".format(label_ranking_average_precision_score(y_test.todense(), y_pred)))\nprint(\"Ranking loss : {:.3f}\".format(label_ranking_loss(y_test.todense(), y_pred)))\nprint(\"Coverage_error : {:.3f}\".format(coverage_error(y_test.todense(), y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0fcf027f00a7031dd7dc7d25c0c6ff362c39954b"},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],\n                      title='Confusion matrix, without normalization')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}